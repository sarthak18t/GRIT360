GRIT360: Gated Relative-position and Importance-aware Transformer for No-Reference 360Â° Quality Assessment
---
ðŸ“˜ Abstract
---

Immersive formats such as 360Â° images and virtual reality have seen widespread adoption in modern broadcasting and adaptive streaming applications, where maintaining perceptual visual quality is essential for user experience. In video technology systems, 360Â° images serve as fundamental components for immersive video content, requiring robust quality assessment mechanisms that operate within real-time broadcasting constraints. Unlike traditional planar images, omnidirectional content presents unique challengesâ€”including spherical distortions, stitching artifacts, and non-uniform perceptual saliencyâ€”that conventional quality metrics cannot model effectively. These challenges become particularly pronounced in video streaming applications where 360Â° image quality directly influences viewport-based video encoding decisions. To address these issues, we propose GRIT360, a no-reference image quality assessment framework specifically designed for omnidirectional images. GRIT360 divides each equirectangular image into 120 structured viewports and applies a perceptual bottom-masking strategy to discard geometrically distorted regions. These viewports are processed through a hierarchical Swin Transformer backbone to extract multi-scale spatial features.A novel Viewport-Weighted Feature Modulation (VWFM) module adaptively scales viewport features using learnable importance weights and gated position-aware enhancement, enabling content-adaptive quality prediction without requiring external saliency data. Additionally, a trainable viewport weighting mechanism dynamically adjusts the contribution of each region during feature fusion and quality regression. GRIT360 adopts a dual-level prediction scheme that estimates both global image quality and viewport-level perceptual fidelity. Evaluations on three public datasets (CVIQ, OIQA, and ODI-IQA) demonstrate that GRIT360 achieves state-of-the-art performance. On ODI-IQA, it achieves PLCC and SRCC scores of 0.973 and 0.968, respectively, which confirms its suitability for deployment in video technology applications, including immersive broadcasting systems and adaptive streaming platforms.
